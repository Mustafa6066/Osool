"""
Psychology Layer for AMR - "The Wolf's Eye"
--------------------------------------------
Extracts psychological state from user messages to enable
psychology-aware selling tactics.

States:
- FOMO: Fear of Missing Out - responds to scarcity
- RISK_AVERSE: Safety-focused - needs reassurance
- GREED_DRIVEN: ROI-focused - responds to gains
- ANALYSIS_PARALYSIS: Overthinking - needs simplification
- IMPULSE_BUYER: Quick decisions - reduce friction
- TRUST_DEFICIT: Skeptical - needs proof/verification
"""

import logging
import re
from enum import Enum
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


class PsychologicalState(Enum):
    """User's emotional decision-making driver."""
    FOMO = "fomo"                        # Fear of Missing Out
    RISK_AVERSE = "risk_averse"          # Safety-focused
    GREED_DRIVEN = "greed_driven"        # ROI-focused
    ANALYSIS_PARALYSIS = "analysis_paralysis"  # Overthinking
    IMPULSE_BUYER = "impulse_buyer"      # Quick decisions
    TRUST_DEFICIT = "trust_deficit"      # Skeptical
    SKEPTICISM = "skepticism"            # Questions market data validity
    NEUTRAL = "neutral"                  # No clear signal


class ObjectionType(Enum):
    """V2: Granular objection classification for specific responses."""
    FINANCIAL = "financial"       # "Can I afford the installments?"
    TRUST = "trust"               # "Will the developer deliver?"
    MARKET = "market"             # "Will the bubble burst?"
    TIMING = "timing"             # "Is now a good time?"
    LOCATION = "location"         # "Is this area good?"
    LEGAL = "legal"               # "Are the papers clean?"
    NONE = "none"                 # No specific objection


class UrgencyLevel(Enum):
    """How soon user needs to act."""
    BROWSING = "browsing"       # 0-20% urgency
    EXPLORING = "exploring"     # 20-40% urgency
    EVALUATING = "evaluating"   # 40-60% urgency
    READY_TO_ACT = "ready"      # 60-80% urgency
    URGENT = "urgent"           # 80-100% urgency


@dataclass
class PsychologyProfile:
    """
    V2: Enhanced psychological profile with emotional trajectory.
    
    Upgrades:
    - dominant_trait: Session-wide personality (not just current message)
    - emotional_momentum: Tracks if user is warming up or cooling down
    - specific_objection: Granular objection type for targeted responses
    """
    primary_state: PsychologicalState
    secondary_state: Optional[PsychologicalState] = None
    urgency_level: UrgencyLevel = UrgencyLevel.EXPLORING
    confidence_score: float = 0.5  # 0-1
    detected_triggers: List[str] = field(default_factory=list)
    recommended_tactics: List[str] = field(default_factory=list)
    
    # V2 Superhuman Upgrades
    dominant_trait: Optional[PsychologicalState] = None  # Session personality
    emotional_momentum: str = "static"  # "warming_up", "cooling_down", "static"
    specific_objection: ObjectionType = ObjectionType.NONE  # Granular objection

    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "primary_state": self.primary_state.value,
            "secondary_state": self.secondary_state.value if self.secondary_state else None,
            "urgency_level": self.urgency_level.value,
            "confidence_score": round(self.confidence_score, 2),
            "detected_triggers": self.detected_triggers,
            "recommended_tactics": self.recommended_tactics,
            # V2 fields
            "dominant_trait": self.dominant_trait.value if self.dominant_trait else None,
            "emotional_momentum": self.emotional_momentum,
            "specific_objection": self.specific_objection.value
        }


# Psychology detection patterns - Arabic and English keywords
PSYCHOLOGY_PATTERNS = {
    PsychologicalState.FOMO: {
        "keywords_ar": [
            "Ù‡ÙŠØ®Ù„Øµ", "ÙØ§Ø¶Ù„ ÙƒØ§Ù…", "Ù‡ØªØ®Ù„Øµ", "Ù…Ø­Ø¯ÙˆØ¯", "Ø¢Ø®Ø± ÙØ±ØµØ©",
            "Ù†Ø§Ø³ ØªØ§Ù†ÙŠØ©", "Ø­Ø¯ ØªØ§Ù†ÙŠ", "Ù‡ÙŠØ±ÙØ¹", "Ø²ÙŠØ§Ø¯Ø©", "Ø§Ù„Ø³Ø¹Ø± Ù‡ÙŠØ²ÙŠØ¯",
            "Ù„Ø­Ø¯ Ø¥Ù…ØªÙ‰", "Ù…ØªØ§Ø­ Ù„Ø­Ø¯ Ø¥Ù…ØªÙ‰", "Ø§Ù„Ø­Ù‚", "ÙØ±ØµØ©"
        ],
        "keywords_en": [
            "limited", "running out", "last chance", "hurry",
            "others interested", "price increase", "how many left",
            "selling fast", "won't last", "before it's gone"
        ],
        "signals": [
            "asking_about_availability_multiple_times",
            "mentioning_competitor_properties",
            "asking_how_many_left",
            "rush_language"
        ],
        "recommended_tactics": ["scarcity", "insider"],
        "weight": 1.0
    },
    PsychologicalState.RISK_AVERSE: {
        "keywords_ar": [
            "Ø®Ø§ÙŠÙ", "Ù…Ø®Ø§Ø·Ø±", "Ø£Ù…Ø§Ù†", "Ø¶Ù…Ø§Ù†", "Ù…ÙˆØ«ÙˆÙ‚", "ØªØ³Ù„ÙŠÙ…",
            "Ù…Ø¶Ù…ÙˆÙ†", "Ù†ØµØ¨", "Ø§Ø­ØªÙŠØ§Ù„", "Ù…Ø´Ø§ÙƒÙ„", "Ù‚Ø§Ù†ÙˆÙ†ÙŠ", "Ø¹Ù‚Ø¯",
            "Ù‚Ù„Ù‚Ø§Ù†", "Ù…ØªØ±Ø¯Ø¯", "Ù…Ø´ Ù…ØªØ£ÙƒØ¯", "Ø£Ø¶Ù…Ù†", "Ø§Ù„Ù…Ø§Ø¯Ø© 114",
            # Bank Certificate comparison keywords (key Egyptian market signal)
            "Ø´Ù‡Ø§Ø¯Ø©", "Ø´Ù‡Ø§Ø¯Ø§Øª", "Ø§Ù„Ø¨Ù†Ùƒ", "ÙØ§ÙŠØ¯Ø©", "ÙÙˆØ§Ø¦Ø¯", "ÙˆØ¯Ø§ÙŠØ¹",
            "Ø£Ø­Ø³Ù† Ù…Ù† Ø§Ù„Ø¨Ù†Ùƒ", "Ø§Ù„Ø¨Ù†Ùƒ ÙˆÙ„Ø§ Ø¹Ù‚Ø§Ø±", "ÙÙ„ÙˆØ³ÙŠ ÙÙŠ Ø§Ù„Ø¨Ù†Ùƒ"
        ],
        "keywords_en": [
            "safe", "secure", "guarantee", "trusted", "delivery",
            "scam", "fraud", "legal", "contract", "worried",
            "concerned", "protection", "risk", "reliable",
            # Bank Certificate comparison keywords
            "certificate", "bank interest", "deposit", "CD rate",
            "better than bank", "bank vs property", "27%", "interest rate"
        ],
        "signals": [
            "asking_about_developer_reputation",
            "mentioning_scams",
            "asking_for_proof",
            "legal_questions",
            "comparing_to_bank_deposits"  # New signal
        ],
        "recommended_tactics": ["authority", "legal_protection", "inflation_comparison"],
        "weight": 1.0
    },
    PsychologicalState.GREED_DRIVEN: {
        "keywords_ar": [
            "Ø¹Ø§Ø¦Ø¯", "Ø±Ø¨Ø­", "Ø§Ø³ØªØ«Ù…Ø§Ø±", "Ø¥ÙŠØ¬Ø§Ø±", "Ù‡ÙŠØ²ÙŠØ¯", "Ù‡ÙŠØ¬ÙŠØ¨ ÙƒØ§Ù…",
            "ROI", "Ø¯Ø®Ù„", "Ù…ÙƒØ³Ø¨", "ÙÙ„ÙˆØ³", "ØªØ¶Ø®Ù…", "Ø¯Ù‡Ø¨", "Ø¯ÙˆÙ„Ø§Ø±",
            "Ø£Ø­Ø³Ù† Ø§Ø³ØªØ«Ù…Ø§Ø±", "Ù‡ÙŠØ·Ù„Ø¹ ÙƒØ§Ù…"
        ],
        "keywords_en": [
            "roi", "profit", "investment", "rental", "appreciation",
            "returns", "income", "gains", "money", "yield",
            "inflation", "hedge", "portfolio", "resale"
        ],
        "signals": [
            "multiple_roi_questions",
            "comparing_investment_options",
            "asking_about_resale",
            "mentioning_other_investments"
        ],
        "recommended_tactics": ["vision", "roi_focused"],
        "weight": 1.0
    },
    PsychologicalState.ANALYSIS_PARALYSIS: {
        "keywords_ar": [
            "Ù…Ø­ØªØ§Ø¬ Ø£ÙÙƒØ±", "Ù…Ø´ Ù…ØªØ£ÙƒØ¯", "ÙƒØªÙŠØ± Ø£ÙˆÙŠ", "Ù…Ø­ØªØ§Ø±",
            "Ø¥ÙŠÙ‡ Ø§Ù„ÙØ±Ù‚", "Ù‚Ø§Ø±Ù†", "Ø£Ø­Ø³Ù† ÙˆØ§Ø­Ø¯Ø©", "Ø¥ÙŠÙ‡ Ø±Ø£ÙŠÙƒ",
            "Ù…Ø´ Ø¹Ø§Ø±Ù Ø£Ø®ØªØ§Ø±", "ØµØ¹Ø¨", "Ù…Ø¹Ù‚Ø¯"
        ],
        "keywords_en": [
            "need to think", "not sure", "too many options",
            "confused", "difference", "compare", "best one",
            "which one", "hard to decide", "complex", "overwhelmed"
        ],
        "signals": [
            "asking_same_question_multiple_times",
            "requesting_many_comparisons",
            "long_decision_time"
        ],
        "recommended_tactics": ["simplify", "authority"],
        "weight": 0.8
    },
    PsychologicalState.IMPULSE_BUYER: {
        "keywords_ar": [
            "Ø¹Ø§ÙŠØ² Ø¯Ù„ÙˆÙ‚ØªÙŠ", "Ø­Ø§Ù„Ø§Ù‹", "Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡", "ÙÙˆØ±Ø§Ù‹", "Ø£Ø­Ø¬Ø²",
            "Ø®Ù„Ø§Øµ Ù‚Ø±Ø±Øª", "Ù…Ø§Ø´ÙŠ", "ØªÙ…Ø§Ù…", "Ù…ÙˆØ§ÙÙ‚", "Ù‡Ù…Ø¶ÙŠ"
        ],
        "keywords_en": [
            "now", "today", "immediately", "book it", "decided",
            "let's go", "done", "agreed", "sign", "ready"
        ],
        "signals": [
            "quick_responses",
            "minimal_questions",
            "immediate_action_language"
        ],
        "recommended_tactics": ["close_fast", "reduce_friction"],
        "weight": 0.9
    },
    PsychologicalState.TRUST_DEFICIT: {
        "keywords_ar": [
            "Ø¥Ø²Ø§ÙŠ Ø£Ø«Ù‚", "Ù…ÙŠÙ† ÙŠØ¶Ù…Ù†", "Ø³Ù…Ø¹Øª Ø¥Ù†", "Ù†Ø§Ø³ Ø§ØªÙ†ØµØ¨Øª",
            "Ø§Ù„Ù…Ø·ÙˆØ± Ø¯Ù‡", "Ø³Ù…Ø¹ØªÙ‡ Ø¥ÙŠÙ‡", "Ù…Ø´Ø§ÙƒÙ„", "ØªØ£Ø®ÙŠØ±",
            "ÙƒÙ„Ø§Ù… Ø³Ù…Ø§Ø³Ø±Ø©", "Ù…Ø´ Ù…ØµØ¯Ù‚", "Ø¨ØªÙ‚Ù†Ø¹Ù†ÙŠ"
        ],
        "keywords_en": [
            "how can i trust", "who guarantees", "heard that",
            "people got scammed", "developer reputation", "problems",
            "delays", "agent talk", "don't believe", "convince me"
        ],
        "signals": [
            "questioning_credentials",
            "mentioning_bad_experiences",
            "skeptical_tone"
        ],
        "recommended_tactics": ["authority", "proof", "testimonials"],
        "weight": 1.0
    }
}

# Urgency detection patterns
URGENCY_PATTERNS = {
    UrgencyLevel.URGENT: {
        "keywords_ar": ["Ù„Ø§Ø²Ù…", "Ø¶Ø±ÙˆØ±ÙŠ", "Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡", "Ø­Ø§Ù„Ø§Ù‹", "Ù…Ø³ØªØ¹Ø¬Ù„", "ÙÙˆØ±Ø§Ù‹"],
        "keywords_en": ["must", "urgent", "today", "immediately", "asap", "now"]
    },
    UrgencyLevel.READY_TO_ACT: {
        "keywords_ar": ["Ø¬Ø§Ù‡Ø²", "Ø¹Ø§ÙŠØ² Ø£Ø­Ø¬Ø²", "Ù†Ù…Ø¶ÙŠ", "Ø®Ø·ÙˆØ© Ø¬Ø§ÙŠØ©", "Ø£Ø¯ÙØ¹"],
        "keywords_en": ["ready", "want to book", "next step", "sign", "pay", "reserve"]
    },
    UrgencyLevel.EVALUATING: {
        "keywords_ar": ["Ø¨Ù‚Ø§Ø±Ù†", "Ø¨ÙÙƒØ±", "Ù…Ø­ØªØ§Ø¬ Ø£Ø´ÙˆÙ", "Ù‚Ø¨Ù„ Ù…Ø§ Ø£Ù‚Ø±Ø±"],
        "keywords_en": ["comparing", "thinking", "need to see", "before deciding"]
    },
    UrgencyLevel.EXPLORING: {
        "keywords_ar": ["Ø¨Ø¯ÙˆØ±", "Ø¹Ø§ÙŠØ² Ø£Ø¹Ø±Ù", "Ø¥ÙŠÙ‡ Ø§Ù„Ù…ØªØ§Ø­", "ÙÙŠÙ‡ Ø¥ÙŠÙ‡"],
        "keywords_en": ["looking for", "want to know", "what's available", "show me"]
    },
    UrgencyLevel.BROWSING: {
        "keywords_ar": ["Ø¨ØªÙØ±Ø¬", "Ù„Ø³Ù‡", "Ø¨Ø¹Ø¯ÙŠÙ†", "Ù…Ø´ Ù…Ø³ØªØ¹Ø¬Ù„"],
        "keywords_en": ["just browsing", "later", "not in a hurry", "someday"]
    }
}

# V2: OBJECTION PATTERNS for granular classification
OBJECTION_PATTERNS = {
    ObjectionType.FINANCIAL: {
        "keywords_ar": [
            "Ø£Ù‚Ø³Ø·", "Ø£Ù‚Ø¯Ø± Ø£Ø¯ÙØ¹", "Ø§Ù„Ø£Ù‚Ø³Ø§Ø·", "Ù…Ù‚Ø¯Ù…", "ÙƒØ§Ø´", "ÙÙ„ÙˆØ³", "Ù…ÙŠØ²Ø§Ù†ÙŠØ©",
            "ØºØ§Ù„ÙŠ", "Ø±Ø®ÙŠØµ", "Ø§Ù„Ø³Ø¹Ø± Ø¹Ø§Ù„ÙŠ", "Ù…Ø´ Ù‚Ø§Ø¯Ø±", "Ø§Ù„Ø¯ÙØ¹", "Ø§Ù„ØªÙ…ÙˆÙŠÙ„"
        ],
        "keywords_en": [
            "afford", "installments", "down payment", "budget", "expensive",
            "financing", "payment plan", "cash", "price too high", "can't pay"
        ]
    },
    ObjectionType.TRUST: {
        "keywords_ar": [
            "Ø§Ù„Ù…Ø·ÙˆØ±", "ØªØ³Ù„ÙŠÙ…", "ØªØ£Ø®ÙŠØ±", "Ù†ØµØ¨", "Ø³Ù…Ø¹Ø©", "Ù…ÙˆØ«ÙˆÙ‚",
            "Ù†Ø§Ø³ Ø§ØªÙ†ØµØ¨Øª", "Ù‡ÙŠØ³Ù„Ù…", "Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ³Ù„ÙŠÙ…"
        ],
        "keywords_en": [
            "developer", "delivery", "delay", "scam", "reputation", "reliable",
            "will they deliver", "track record", "guarantee delivery"
        ]
    },
    ObjectionType.MARKET: {
        "keywords_ar": [
            "Ø§Ù„ÙÙ‚Ø§Ø¹Ø©", "Ù‡ÙŠÙ†Ø²Ù„", "Ø§Ù„Ø³ÙˆÙ‚ Ù‡ÙŠÙ‚Ø¹", "Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù‡ØªÙ†Ø²Ù„", "Ù…Ø³ØªÙ‚Ø±",
            "ÙˆÙ‚Øª Ù…Ù†Ø§Ø³Ø¨", "Ø§Ù„ØªØ¶Ø®Ù…", "Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯"
        ],
        "keywords_en": [
            "bubble", "crash", "prices will drop", "market stable", "good time",
            "inflation", "economy", "will prices fall"
        ]
    },
    ObjectionType.TIMING: {
        "keywords_ar": [
            "Ø£Ø³ØªÙ†Ù‰", "Ø¨Ø¹Ø¯ÙŠÙ†", "Ù…Ø´ Ø§Ù„ÙˆÙ‚Øª", "Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ø¬Ø§ÙŠØ©", "Ù„Ø³Ù‡ Ø¨Ø¯Ø±ÙŠ",
            "Ù…Ø´ Ù…Ø³ØªØ¹Ø¬Ù„"
        ],
        "keywords_en": [
            "wait", "later", "not the right time", "next year", "too early",
            "not in a hurry"
        ]
    },
    ObjectionType.LOCATION: {
        "keywords_ar": [
            "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", "Ø§Ù„Ø¬ÙŠØ±Ø§Ù†", "Ø§Ù„Ø®Ø¯Ù…Ø§Øª", "Ù‚Ø±ÙŠØ¨ Ù…Ù†", "Ø¨Ø¹ÙŠØ¯ Ø¹Ù†",
            "Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø¯Ù‡", "ÙÙŠÙ† Ø¨Ø§Ù„Ø¸Ø¨Ø·"
        ],
        "keywords_en": [
            "area", "neighborhood", "services", "close to", "far from",
            "location", "where exactly"
        ]
    },
    ObjectionType.LEGAL: {
        "keywords_ar": [
            "Ø§Ù„Ø¹Ù‚Ø¯", "Ø§Ù„Ø£ÙˆØ±Ø§Ù‚", "Ù‚Ø§Ù†ÙˆÙ†ÙŠ", "ØªØ³Ø¬ÙŠÙ„", "Ù…Ù„ÙƒÙŠØ©", "114",
            "ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ù„ÙƒÙŠØ©", "Ø±Ø®ØµØ©"
        ],
        "keywords_en": [
            "contract", "papers", "legal", "registration", "ownership",
            "law 114", "chain of title", "permit"
        ]
    }
}


def _detect_objection_type(query: str, triggers: List[str]) -> ObjectionType:
    """
    V2: Detect specific objection type for granular response.
    This enables different responses for financial vs trust vs market concerns.
    """
    query_lower = query.lower()
    
    # Score each objection type
    scores = {}
    for objection_type, patterns in OBJECTION_PATTERNS.items():
        score = 0
        for keyword in patterns.get("keywords_ar", []):
            if keyword in query_lower:
                score += 1
        for keyword in patterns.get("keywords_en", []):
            if keyword in query_lower:
                score += 1
        scores[objection_type] = score
    
    # Find highest scoring objection
    best_objection = max(scores, key=scores.get)
    if scores[best_objection] > 0:
        return best_objection
    
    return ObjectionType.NONE


def _calculate_emotional_momentum(history: List[Dict]) -> str:
    """
    V2: Track if user is warming up or cooling down over conversation.
    
    Analyzes state progression across recent messages:
    - warming_up: Moving from skeptical -> engaged
    - cooling_down: Moving from engaged -> skeptical
    - static: No clear trajectory
    """
    if len(history) < 4:
        return "static"
    
    # Positive signals (warming up)
    positive_signals = [
        "Ø¹Ø§ÙŠØ²", "Ø¬Ø§Ù‡Ø²", "Ù…ÙˆØ§ÙÙ‚", "Ø­Ù„Ùˆ", "ØªÙ…Ø§Ù…", "ÙƒÙˆÙŠØ³", "Ù…Ù…ØªØ§Ø²",
        "interested", "ready", "sounds good", "okay", "let's", "show me more"
    ]
    
    # Negative signals (cooling down)
    negative_signals = [
        "Ù…Ø´ Ù…ØªØ£ÙƒØ¯", "Ø¨Ø¹Ø¯ÙŠÙ†", "Ù…Ø­ØªØ§Ø¬ Ø£ÙÙƒØ±", "ØºØ§Ù„ÙŠ", "Ù…Ø´ Ù…Ù‚ØªÙ†Ø¹",
        "not sure", "later", "need to think", "expensive", "not convinced"
    ]
    
    # Count signals in first half vs second half
    recent_history = history[-6:]
    first_half = recent_history[:3]
    second_half = recent_history[3:]
    
    def count_signals(msgs, signals):
        count = 0
        for msg in msgs:
            if msg.get("role") == "user":
                content = msg.get("content", "").lower()
                count += sum(1 for s in signals if s in content)
        return count
    
    first_positive = count_signals(first_half, positive_signals)
    first_negative = count_signals(first_half, negative_signals)
    second_positive = count_signals(second_half, positive_signals)
    second_negative = count_signals(second_half, negative_signals)
    
    # Determine trajectory
    if second_positive > first_positive and second_negative <= first_negative:
        return "warming_up"
    elif second_negative > first_negative and second_positive <= first_positive:
        return "cooling_down"
    
    return "static"


def _calculate_dominant_trait(history: List[Dict]) -> Optional[PsychologicalState]:
    """
    V2: Calculate user's dominant personality trait across entire session.
    
    This is different from primary_state (current message) - it tracks
    the overall pattern across all messages.
    """
    if len(history) < 3:
        return None
    
    # Count state occurrences across history
    state_counts = {state: 0 for state in PsychologicalState}
    
    for msg in history:
        if msg.get("role") == "user":
            content = msg.get("content", "").lower()
            
            # Simple keyword matching for each state
            for state, patterns in PSYCHOLOGY_PATTERNS.items():
                for keyword in patterns.get("keywords_ar", []) + patterns.get("keywords_en", []):
                    if keyword in content:
                        state_counts[state] += 1
    
    # Find most common state
    if max(state_counts.values()) > 0:
        dominant = max(state_counts, key=state_counts.get)
        if state_counts[dominant] >= 2:  # Minimum threshold
            return dominant
    
    return None


async def semantic_classify_emotion(query: str, history_context: str = "") -> Tuple[PsychologicalState, float]:
    """
    V2: Semantic fallback using LLM when keyword matching returns NEUTRAL/low confidence.
    
    This catches nuanced expressions like:
    - "I'm not sure if I want to commit my life savings to a hole in the ground"
    (Should be RISK_AVERSE, but no keywords match)
    
    Uses Claude Haiku for speed and cost efficiency.
    """
    try:
        from langchain_anthropic import ChatAnthropic
        
        classifier = ChatAnthropic(
            model="claude-3-haiku-20240307",
            temperature=0,
            max_tokens=100
        )
        
        classification_prompt = f"""Classify this Egyptian real estate buyer's emotional state.

User message: "{query}"
Recent context: {history_context[:500] if history_context else "None"}

Classify into ONE of these states:
- FOMO: Fear of missing out, wants to act fast
- RISK_AVERSE: Worried about safety, scams, delivery
- GREED_DRIVEN: Focused on ROI, profit, investment returns
- ANALYSIS_PARALYSIS: Overthinking, can't decide
- IMPULSE_BUYER: Ready to act immediately
- TRUST_DEFICIT: Skeptical of claims, needs proof
- SKEPTICISM: Questions market data validity
- NEUTRAL: No clear emotional driver

Respond with ONLY:
{{"state": "STATE_NAME", "confidence": 0.X}}"""

        response = await classifier.ainvoke(classification_prompt)
        
        # Parse response
        import json
        result = json.loads(response.content)
        state_name = result.get("state", "NEUTRAL").upper()
        confidence = float(result.get("confidence", 0.5))
        
        # Map to enum
        state_map = {
            "FOMO": PsychologicalState.FOMO,
            "RISK_AVERSE": PsychologicalState.RISK_AVERSE,
            "GREED_DRIVEN": PsychologicalState.GREED_DRIVEN,
            "ANALYSIS_PARALYSIS": PsychologicalState.ANALYSIS_PARALYSIS,
            "IMPULSE_BUYER": PsychologicalState.IMPULSE_BUYER,
            "TRUST_DEFICIT": PsychologicalState.TRUST_DEFICIT,
            "SKEPTICISM": PsychologicalState.SKEPTICISM,
            "NEUTRAL": PsychologicalState.NEUTRAL
        }
        
        return state_map.get(state_name, PsychologicalState.NEUTRAL), confidence
        
    except Exception as e:
        logger.warning(f"Semantic classification failed: {e}")
        return PsychologicalState.NEUTRAL, 0.3


def analyze_psychology(
    query: str,
    history: List[Dict],
    intent: Optional[Dict] = None
) -> PsychologyProfile:
    """
    Analyze user's psychological state from query and history.

    Args:
        query: Current user message
        history: Conversation history
        intent: Extracted intent from perception layer

    Returns:
        PsychologyProfile with detected state and recommendations
    """
    query_lower = query.lower()

    # Combine current query with recent history for analysis
    all_text = query_lower
    for msg in history[-5:]:  # Last 5 messages
        if msg.get("role") == "user":
            all_text += " " + msg.get("content", "").lower()

    # Score each psychological state
    state_scores: Dict[PsychologicalState, float] = {}
    detected_triggers: Dict[PsychologicalState, List[str]] = {}

    for state, patterns in PSYCHOLOGY_PATTERNS.items():
        score = 0.0
        triggers = []

        # Check Arabic keywords
        for keyword in patterns.get("keywords_ar", []):
            if keyword in all_text:
                score += 1.0 * patterns["weight"]
                triggers.append(f"ar:{keyword}")

        # Check English keywords
        for keyword in patterns.get("keywords_en", []):
            if keyword in all_text:
                score += 1.0 * patterns["weight"]
                triggers.append(f"en:{keyword}")

        state_scores[state] = score
        detected_triggers[state] = triggers

    # Find primary and secondary states
    sorted_states = sorted(state_scores.items(), key=lambda x: x[1], reverse=True)

    primary_state = PsychologicalState.NEUTRAL
    secondary_state = None
    confidence = 0.0
    all_triggers = []

    if sorted_states[0][1] > 0:
        primary_state = sorted_states[0][0]
        confidence = min(sorted_states[0][1] / 3.0, 1.0)  # Normalize to 0-1
        all_triggers = detected_triggers[primary_state]

        if len(sorted_states) > 1 and sorted_states[1][1] > 0:
            secondary_state = sorted_states[1][0]
            all_triggers.extend(detected_triggers[secondary_state])

    # Detect urgency level
    urgency = _detect_urgency(query_lower, history)

    # Get recommended tactics
    tactics = PSYCHOLOGY_PATTERNS.get(primary_state, {}).get("recommended_tactics", [])
    if secondary_state:
        tactics.extend(PSYCHOLOGY_PATTERNS.get(secondary_state, {}).get("recommended_tactics", []))
    tactics = list(set(tactics))  # Remove duplicates

    # NEW: Sarcasm Detector (The "Human Touch" Framework)
    # 1. Direct verbal signals
    sarcasm_triggers = ["sure you are", "yeah right", "tell me another one", "obvious", "robot", "lies", "joke", "funny", "Ù†ÙƒØªØ©", "Ø¨ØªÙ‡Ø²Ø±", "Ù…ØµØ¯Ù‚Ùƒ", "Ø§ÙƒÙŠØ¯ Ø·Ø¨Ø¹Ø§"]
    is_sarcastic = any(x in query.lower() for x in sarcasm_triggers)
    
    # 2. Contextual Sarcasm (Price Sensitivity)
    if not is_sarcastic:
        is_sarcastic = _detect_contextual_sarcasm(query, history)

    if is_sarcastic:
        primary_state = PsychologicalState.TRUST_DEFICIT
        confidence = 0.0 # Force low confidence to trigger cautious response
        tactics = ["humility", "proof_only", "acknowledge_skepticism"]
        all_triggers.append("detected_sarcasm")
        logger.info("ğŸ­ Sarcasm Detected: Overriding state to TRUST_DEFICIT")

    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # V2 SUPERHUMAN UPGRADES
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    # 1. Calculate Dominant Trait (session-wide personality)
    dominant_trait = _calculate_dominant_trait(history)
    
    # 2. Calculate Emotional Momentum (warming up vs cooling down)
    emotional_momentum = _calculate_emotional_momentum(history)
    
    # 3. Detect Specific Objection Type (granular risk classification)
    specific_objection = _detect_objection_type(query, all_triggers)
    
    logger.info(f"ğŸ§  V2 Psychology: dominant={dominant_trait}, momentum={emotional_momentum}, objection={specific_objection.value}")

    profile = PsychologyProfile(
        primary_state=primary_state,
        secondary_state=secondary_state,
        urgency_level=urgency,
        confidence_score=confidence,
        detected_triggers=all_triggers[:5],  # Limit to top 5 triggers
        recommended_tactics=tactics,
        # V2 fields
        dominant_trait=dominant_trait,
        emotional_momentum=emotional_momentum,
        specific_objection=specific_objection
    )

    logger.info(f"ğŸ§  Psychology: {primary_state.value} (conf: {confidence:.2f}), Urgency: {urgency.value}")

    return profile


def _detect_contextual_sarcasm(query: str, history: List[Dict]) -> bool:
    """
    Detect if user is being sarcastic based on context.
    Example: High price in history + User says "Cheap/Deal".
    """
    if not history:
        return False
        
    last_ai_msg = next((m for m in reversed(history) if m["role"] == "assistant"), None)
    if not last_ai_msg:
        return False
        
    last_content = last_ai_msg.get("content", "").lower()
    query_lower = query.lower()
    
    # Check if last message had high price (e.g. > 10M or mention of millions)
    has_high_price = "million" in last_content or "Ù…Ù„ÙŠÙˆÙ†" in last_content
    
    # Check if user response is suspiciously positive/dismissive
    positive_words_ar = ["Ø±Ø®ÙŠØµ", "Ø¨Ù„Ø§Ø´", "Ù„Ù‚Ø·Ø©", "ØªØ­ÙØ©", "Ø¨Ø³ÙŠØ·"]
    positive_words_en = ["cheap", "steal", "nothing", "pennies", "pocket change"]
    
    is_positive = any(w in query_lower for w in positive_words_ar + positive_words_en)
    
    # Heuristic: High Price + "Cheap" = Sarcasm
    if has_high_price and is_positive:
        # Check against negation (e.g. "not cheap")
        if "not" in query_lower or "Ù…Ø´" in query_lower:
            return False
        return True
        
    return False


def _detect_urgency(query: str, history: List[Dict]) -> UrgencyLevel:
    """Detect urgency level from query and history."""

    # Check from most urgent to least
    for level in [UrgencyLevel.URGENT, UrgencyLevel.READY_TO_ACT,
                  UrgencyLevel.EVALUATING, UrgencyLevel.EXPLORING]:
        patterns = URGENCY_PATTERNS.get(level, {})

        for keyword in patterns.get("keywords_ar", []):
            if keyword in query:
                return level

        for keyword in patterns.get("keywords_en", []):
            if keyword in query:
                return level

    # Default based on conversation length
    if len(history) > 10:
        return UrgencyLevel.EVALUATING
    elif len(history) > 5:
        return UrgencyLevel.EXPLORING
    else:
        return UrgencyLevel.BROWSING


def get_psychology_context_for_prompt(profile: PsychologyProfile) -> str:
    """
    Generate context string to inject into Claude's system prompt.

    Args:
        profile: The detected psychology profile

    Returns:
        Context string for the AI prompt
    """
    state = profile.primary_state
    urgency = profile.urgency_level

    context_parts = [
        f"\n[PSYCHOLOGY_MODE: {state.value.upper()}]"
    ]

    # State-specific instructions
    if state == PsychologicalState.FOMO:
        context_parts.append("""
- User is susceptible to scarcity. Use time-limited language.
- Mention: "Ø§Ù„Ø­Ù‚ Ø§Ù„ÙØ±ØµØ© Ø¯ÙŠ" (Catch this opportunity)
- Highlight: Limited units, upcoming price increases, other interested buyers
- Urgency phrases: "Ù‚Ø¨Ù„ Ù…Ø§ ØªØ®Ù„Øµ", "Ø§Ù„Ø³Ø¹Ø± Ø¯Ù‡ Ù…Ø´ Ù‡ÙŠÙØ¶Ù„"
""")

    elif state == PsychologicalState.RISK_AVERSE:
        context_parts.append("""
- User needs reassurance and safety. Lead with protection.
- Mention: Developer reputation, delivery track record, Law 114 compliance
- Use: "Ø¹Ù„Ù‰ Ù…Ø³Ø¤ÙˆÙ„ÙŠØªÙŠ", "Ø£Ù†Ø§ Ø¨Ø­Ù…ÙŠÙƒ", "Ø§Ù„Ø¹Ù‚Ø¯ Ø³Ù„ÙŠÙ…"
- Offer: Contract review, legal verification, testimonials
""")

    elif state == PsychologicalState.GREED_DRIVEN:
        context_parts.append("""
- User is ROI-focused. Lead with numbers and returns.
- Show: ROI projections, rental yields, appreciation forecasts
- Compare: Property vs Cash vs Gold (Inflation Killer)
- Use: "Ø§Ù„Ø¹Ø§Ø¦Ø¯", "Ø§Ù„Ù€ ROI", "Ù‡ØªÙƒØ³Ø¨ ÙƒØ§Ù… ÙÙŠ Ø§Ù„Ø³Ù†Ø©"
""")

    elif state == PsychologicalState.ANALYSIS_PARALYSIS:
        context_parts.append("""
- User is overthinking. Simplify and guide decisively.
- Limit options to TOP 2 maximum
- Make the recommendation clear: "Ù„Ùˆ Ø£Ù†Ø§ Ù…ÙƒØ§Ù†Ùƒ..."
- Reduce cognitive load, be direct about best choice
""")

    elif state == PsychologicalState.IMPULSE_BUYER:
        context_parts.append("""
- User wants to act fast. Reduce friction.
- Skip lengthy explanations, get to booking/payment
- Provide quick next step: "Ø®Ù„ÙŠÙ†Ø§ Ù†Ø­Ø¬Ø² Ø¯Ù„ÙˆÙ‚ØªÙŠ"
- Don't over-explain, maintain momentum
""")

    elif state == PsychologicalState.TRUST_DEFICIT:
        context_parts.append("""
- User is skeptical. Build credibility with proof.
- Reference: "Ø§Ù„Ø³ÙŠØ³ØªÙ… Ø¨ØªØ§Ø¹ÙŠ Ø¨ÙŠÙ‚ÙˆÙ„" (data-backed claims)
- Offer: Verification, references, developer portfolio
- Don't push hard, build trust first
""")

    # Urgency context
    if urgency == UrgencyLevel.URGENT or urgency == UrgencyLevel.READY_TO_ACT:
        context_parts.append("""
[URGENCY: HIGH]
- User is ready to act. Move to closing.
- Provide booking/reservation link or next step
- Don't introduce new options, focus on closing current interest
""")

    return "\n".join(context_parts)


# Singleton-style function for easy import
def get_psychology_analyzer():
    """Return the analyze_psychology function for external use."""
    return analyze_psychology


class Strategy(Enum):
    """Sales strategy based on psychological state."""
    TRUST_BUILDING = "trust_building"    # Focus on Law 114, Developer Reputation
    ROI_FOCUSED = "roi_focused"          # Focus on 25% annual gain, inflation hedge
    SCARCITY_PITCH = "scarcity_pitch"    # Focus on "Last unit", "Price increase tomorrow"
    CONSULTATIVE = "consultative"        # Educational, guiding approach
    CLOSE_FAST = "close_fast"            # Reduce friction, move to action
    SIMPLIFY = "simplify"                # Cut options, make recommendation
    # V2 Granular Strategies
    FINANCIAL_REASSURANCE = "financial_reassurance"  # Payment plan, affordability
    MARKET_ANCHORING = "market_anchoring"            # Inflation data, market proof
    LOCATION_EDUCATION = "location_education"        # Area value, development plans


def determine_strategy(
    psychology: PsychologyProfile,
    has_properties: bool = True,
    top_property_verdict: str = "FAIR"
) -> Dict[str, Any]:
    """
    V2: Enhanced strategy selector with granular objection handling.
    
    This is the core "Wolf" strategy selector that maps emotional
    state + specific objection to the optimal persuasion angle.
    
    Args:
        psychology: The detected psychology profile
        has_properties: Whether we have properties to show
        top_property_verdict: Best property verdict (BARGAIN/FAIR/PREMIUM)
    
    Returns:
        Strategy dict with angle and talking points
    """
    state = psychology.primary_state
    urgency = psychology.urgency_level
    objection = psychology.specific_objection  # V2: Granular objection
    momentum = psychology.emotional_momentum   # V2: Emotional trajectory
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # V2: GRANULAR OBJECTION HANDLING
    # Different responses for financial vs trust vs market concerns
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    if state == PsychologicalState.RISK_AVERSE:
        # V2: Check SPECIFIC type of risk
        if objection == ObjectionType.FINANCIAL:
            strategy = Strategy.FINANCIAL_REASSURANCE
            angle = "affordability"
            talking_points = [
                "Ø®Ù„ÙŠÙ†ÙŠ Ø£ÙˆØ±ÙŠÙƒ Ø®Ø·Ø© Ø§Ù„Ø³Ø¯Ø§Ø¯ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ - Ù…Ù…ÙƒÙ† ØªØ¨Ø¯Ø£ Ø¨Ù…Ù‚Ø¯Ù… 10% Ø¨Ø³.",
                "Ø§Ù„Ø£Ù‚Ø³Ø§Ø· Ø¹Ù„Ù‰ 8 Ø³Ù†ÙŠÙ†ØŒ ÙŠØ¹Ù†ÙŠ Ø§Ù„Ø´Ù‡Ø±ÙŠ Ø£Ù‚Ù„ Ù…Ù† Ø¥ÙŠØ¬Ø§Ø± Ø´Ù‚Ø© ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©.",
                "Ø­Ø§Ø³Ø¨Ù„Ùƒ: Ø§Ù„Ù‚Ø³Ø· Ø§Ù„Ø´Ù‡Ø±ÙŠ Ù‡ÙŠÙƒÙˆÙ† Ø­ÙˆØ§Ù„ÙŠ [X] Ø¬Ù†ÙŠÙ‡. Ø¯Ù‡ ÙÙŠ Ø­Ø¯ÙˆØ¯ Ù…ÙŠØ²Ø§Ù†ÙŠØªÙƒØŸ",
                "ÙÙŠÙ‡ ØªÙ…ÙˆÙŠÙ„ Ø¨Ù†ÙƒÙŠ ÙƒÙ…Ø§Ù† Ù„Ùˆ Ù…Ø­ØªØ§Ø¬ - Ø£Ù†Ø§ Ø¨Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø§Ù„ÙˆØ±Ù‚."
            ]
        elif objection == ObjectionType.LEGAL:
            strategy = Strategy.TRUST_BUILDING
            angle = "legal_protection"
            talking_points = [
                "Ø³Ø¤Ø§Ù„ Ù…Ù…ØªØ§Ø². Ø§Ø¨Ø¹ØªÙ„ÙŠ ÙƒÙˆØ¯ Ø§Ù„ÙˆØ­Ø¯Ø© Ø£Ùˆ Ø§Ù„Ø¹Ù‚Ø¯ØŒ ÙˆØ£Ù†Ø§ Ù‡Ø´ØºÙ„ Ø¹Ù„ÙŠÙ‡ ÙØ­Øµ Ù‚Ø§Ù†ÙˆÙ† 114.",
                "Ø¨ØªØ£ÙƒØ¯ Ù…Ù†: ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ù„ÙƒÙŠØ©ØŒ Ø±Ø®ØµØ© Ø§Ù„Ø¨Ù†Ø§Ø¡ØŒ ÙˆØ´Ø±ÙˆØ· Ø§Ù„ØªØ³Ù„ÙŠÙ….",
                "Ù…Ø´ Ø¨Ù†Ù…Ø¶ÙŠ Ø­Ø§Ø¬Ø© ØºÙŠØ± Ù„Ù…Ø§ Ø§Ù„ÙˆØ±Ù‚ ÙŠØ·Ù„Ø¹ Ù†Ø¶ÙŠÙ 100%.",
                "Law 114 Scanner Ø¨ÙŠÙƒØ´Ù 47 Ù†ÙˆØ¹ Ù…Ø´ÙƒÙ„Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© - Ù…Ø¬Ø§Ù†Ø§Ù‹ Ù„ÙŠÙƒ."
            ]
        elif objection == ObjectionType.TRUST:
            strategy = Strategy.TRUST_BUILDING
            angle = "developer_track_record"
            talking_points = [
                "Ø§Ù„Ù…Ø·ÙˆØ± Ø¯Ù‡ Ø¹Ù†Ø¯Ù‡ track record: 95% ØªØ³Ù„ÙŠÙ… ÙÙŠ Ø§Ù„ÙˆÙ‚ØªØŒ 0 Ù‚Ø¶Ø§ÙŠØ§.",
                "Ø£Ù†Ø§ Ø¨Ø­Ø· Ø³Ù…Ø¹ØªÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ùƒ - Ù…Ø´ Ù‡Ø±Ø´Ø­Ù„Ùƒ Ø­Ø§Ø¬Ø© Ù…Ø´ Ù…Ø¶Ù…ÙˆÙ†Ø©.",
                "ØªØ­Ø¨ Ø£ÙˆØ±ÙŠÙƒ Ù…Ø´Ø§Ø±ÙŠØ¹Ù‡Ù… Ø§Ù„Ù„ÙŠ Ø§ØªØ³Ù„Ù…ØªØŸ Ø¹Ù†Ø¯ÙŠ ØµÙˆØ± ÙˆØªÙ‚ÙŠÙŠÙ…Ø§Øª Ù…Ù† Ø³ÙƒØ§Ù†.",
                "Ø¯Ù‡ Ù…Ù† Ù‚Ø§ÙŠÙ…Ø© Class A developers - Ø§Ù„ÙƒØ¨Ø§Ø± Ø¨Ø³."
            ]
        else:
            # Default RISK_AVERSE handling
            strategy = Strategy.TRUST_BUILDING
            angle = "trust"
            talking_points = [
                "Don't sign anything yet. Send me the contract first; I'll run my Legal Scanner on it.",
                "I utilize a Law 114 Legal Scanner to detect contract loopholes.",
                "This developer has a 95% on-time delivery record. Zero legal violations.",
                "My protocol requires verification on Polygon before I recommend this.",
            ]
            
    elif objection == ObjectionType.MARKET:
        # V2: Market doubt objection (regardless of state)
        strategy = Strategy.MARKET_ANCHORING
        angle = "inflation_proof"
        talking_points = [
            "Ø³Ø¤Ø§Ù„ Ø°ÙƒÙŠ. Ø®Ù„ÙŠÙ†ÙŠ Ø£ÙˆØ±ÙŠÙƒ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©.",
            "Ø§Ù„ØªØ¶Ø®Ù… 33%ØŒ Ø§Ù„Ø´Ù‡Ø§Ø¯Ø§Øª 27%. ÙŠØ¹Ù†ÙŠ Ø§Ù„ÙƒØ§Ø´ Ø¨ÙŠØ®Ø³Ø± 6% Ø³Ù†ÙˆÙŠØ§Ù‹.",
            "Ø§Ù„Ø¹Ù‚Ø§Ø± ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¯ÙŠ Ø²Ø§ÙŠØ¯ 18% Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ù„ÙŠ ÙØ§ØªØª - Ø¯Ù‡ Ù…Ø´ ÙƒÙ„Ø§Ù…ØŒ Ø¯Ù‡ data.",
            "ØªØ­Ø¨ Ø£ÙˆØ±ÙŠÙƒ Ø±Ø³Ù… Ø§Ù„Ù€ Inflation KillerØŸ Ø¨ÙŠÙˆØ¶Ø­ Ø§Ù„ÙØ±Ù‚ Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù…."
        ]
        
    elif objection == ObjectionType.TIMING:
        # V2: Timing concern handling
        strategy = Strategy.SCARCITY_PITCH
        angle = "timing_urgency"
        talking_points = [
            "Ø£ÙÙ‡Ù… Ø§Ù„Ù„ÙŠ Ø¨ØªÙ‚ÙˆÙ„Ù‡. Ø¨Ø³ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¨ØªÙ‚ÙˆÙ„ Ø­Ø§Ø¬Ø© ØªØ§Ù†ÙŠØ©.",
            "Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø²Ø§Ø¯Øª 20% ÙÙŠ Ø¢Ø®Ø± 6 Ø´Ù‡ÙˆØ±. Ø§Ù„Ø§Ø³ØªÙ†Ù‰ = Ø¯ÙØ¹ Ø£ÙƒØªØ±.",
            "Ø§Ù„Ø³ÙŠØ³ØªÙ… Ø¨ØªØ§Ø¹ÙŠ Ø¨ÙŠÙ‚ÙˆÙ„ÙŠ Ø¥Ù† Ø§Ù„Ù…Ø·ÙˆØ± Ù‡ÙŠØ±ÙØ¹ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø¬Ø§ÙŠ.",
            "Ù„Ùˆ Ù…Ø´ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ø©ØŒ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ø­Ø¯Ø¯ ØªØ§Ø±ÙŠØ® Ù†ØªÙƒÙ„Ù… ÙÙŠÙ‡ ØªØ§Ù†ÙŠ."
        ]
        
    elif objection == ObjectionType.LOCATION:
        # V2: Location concern handling
        strategy = Strategy.LOCATION_EDUCATION
        angle = "area_value"
        talking_points = [
            "Ø®Ù„ÙŠÙ†ÙŠ Ø£ÙÙ‡Ù…Ùƒ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¯ÙŠ ÙƒÙˆÙŠØ³:",
            "Ø§Ù„Ø®Ø¯Ù…Ø§Øª: Ù…Ø¯Ø§Ø±Ø³ØŒ Ù…Ø³ØªØ´ÙÙŠØ§ØªØŒ Ù…ÙˆÙ„Ø§Øª - ÙƒÙ„Ù‡ ÙÙŠ 10 Ø¯Ù‚Ø§ÙŠÙ‚.",
            "Ø®Ø·Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø¬Ø§ÙŠØ© Ù‡ØªØ²ÙˆØ¯ Ø§Ù„Ù‚ÙŠÙ…Ø© 15-20% Ø®Ù„Ø§Ù„ 3 Ø³Ù†ÙŠÙ†.",
            "Ø§Ù„Ø¬ÙŠØ±Ø§Ù† Ù‡Ù†Ø§Ùƒ professionals Ùˆ Ø¹Ø§Ø¦Ù„Ø§Øª - community ÙƒÙˆÙŠØ³Ø©."
        ]
        
    elif state == PsychologicalState.GREED_DRIVEN:
        strategy = Strategy.ROI_FOCUSED
        angle = "profit"
        talking_points = [
            "This unit is an 'Inflation Killer'. It generates 2x the return of a bank deposit.",
            "Inflation is 35%. Bank CDs are 27%. You are losing 8% annually. This property stops the bleeding.",
            "Projected ROI is 25% conservative. Including rental yield, you beat Gold.",
            "This is a 'Catch' - math proves it.",
        ]
        
    elif state == PsychologicalState.FOMO:
        strategy = Strategy.SCARCITY_PITCH
        angle = "scarcity"
        talking_points = [
            "There are only 2 units left with this view. The developer raises prices on Sunday.",
            "This price is valid for 48 hours. I've seen the developer's internal memo.",
            "Demand in this zone is up 40%. Waiting = Paying more.",
            "I have 3 other investors looking at this same unit right now.",
        ]
        
    elif state == PsychologicalState.ANALYSIS_PARALYSIS:
        strategy = Strategy.SIMPLIFY
        angle = "decision"
        talking_points = [
            "Ø®Ù„ÙŠÙ†ÙŠ Ø£Ø³Ù‡Ù„Ù‡Ø§ Ø¹Ù„ÙŠÙƒ - Ø¯Ù‡ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„ Ù„ÙŠÙƒ",
            "Ù…Ù† ÙƒÙ„ Ø§Ù„Ù„ÙŠ Ø´ÙˆÙØªÙ‡ØŒ Ø§Ù„ÙˆØ­Ø¯Ø© Ø¯ÙŠ Ø£Ø­Ø³Ù† match",
            "Ù„Ùˆ Ø£Ù†Ø§ Ù…ÙƒØ§Ù†ÙƒØŒ Ù‡Ø®ØªØ§Ø± Ø¯ÙŠ",
            "Ù…ØªØ´ØªØªØ´ Ù†ÙØ³Ùƒ - Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø¯ÙŠ",
        ]
        
    elif state == PsychologicalState.IMPULSE_BUYER:
        strategy = Strategy.CLOSE_FAST
        angle = "action"
        talking_points = [
            "Ø®Ù„ÙŠÙ†Ø§ Ù†Ø­Ø¬Ø² Ø¯Ù„ÙˆÙ‚ØªÙŠ Ø¨Ù…Ù‚Ø¯Ù… Ù‚Ù„ÙŠÙ„",
            "Ø£Ù†Ø§ Ù‡Ø¹Ù…Ù„Ùƒ Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø¬Ø² Ø­Ø§Ù„Ø§Ù‹",
            "Ø§Ù…Ø¶ÙŠ ÙˆØ®Ù„Øµ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹",
            "Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø¬Ø§ÙŠØ© Ø³Ù‡Ù„Ø© - Ø¨Ø³ Ù‡Ù†Ø­ØªØ§Ø¬...",
        ]
        
    elif state == PsychologicalState.TRUST_DEFICIT:
        strategy = Strategy.TRUST_BUILDING
        angle = "proof"
        talking_points = [
            "Before we talk prices, I want to show you the transaction history.",
            "I don't want you to trust me. I want you to trust the data. Here is the Blockchain Verification link for the last unit we sold...",
            "Send me any contract you haveâ€”I'll run my Law 114 Scanner on it for free."
        ]
        
    elif state == PsychologicalState.SKEPTICISM:
        # V2: New SKEPTICISM state handling
        strategy = Strategy.MARKET_ANCHORING
        angle = "data_proof"
        talking_points = [
            "Ø³Ø¤Ø§Ù„ Ù…Ù…ØªØ§Ø². Ø³ÙŠØ¨Ùƒ Ù…Ù† ÙƒÙ„Ø§Ù… Ø§Ù„Ø¨ÙŠØ¹ ÙˆØ®Ù„ÙŠÙ†Ø§ Ù†ØªÙƒÙ„Ù… Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù….",
            "Live Market Pulse: Ø§Ù„ØªØ¶Ø®Ù… 33%ØŒ Ø§Ù„Ø¨Ù†Ùƒ 27%ØŒ ÙŠØ¹Ù†ÙŠ Ø®Ø³Ø§Ø±Ø© 6% Ø³Ù†ÙˆÙŠØ§Ù‹ Ù„Ù„ÙƒØ§Ø´.",
            "Ø§Ù„Ø¹Ù‚Ø§Ø± ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¯ÙŠ Ø²Ø§ÙŠØ¯ [GROWTH_RATE]% - Ø¯Ù‡ data Ù…Ø´ Ø±Ø£ÙŠ.",
            "ØªØ­Ø¨ Ø£ÙˆØ±ÙŠÙƒ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØŸ"
        ]
        
    else:  # NEUTRAL
        strategy = Strategy.CONSULTATIVE
        angle = "guide"
        talking_points = [
            "Ø®Ù„ÙŠÙ†ÙŠ Ø£ÙÙ‡Ù… Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒ Ø§Ù„Ø£ÙˆÙ„",
            "Ø¥ÙŠÙ‡ Ø£Ù‡Ù… Ø­Ø§Ø¬Ø© Ù„ÙŠÙƒ - Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆÙ„Ø§ Ø§Ù„Ø³Ø¹Ø±ØŸ",
            "Ù‡Ù„ Ø¨ØªØ´ØªØ±ÙŠ Ù„Ù„Ø³ÙƒÙ† ÙˆÙ„Ø§ Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±ØŸ",
            "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ø£Ø³Ø§Ø¹Ø¯Ùƒ ØªØ®ØªØ§Ø± ØµØ­",
        ]
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # V2: MOMENTUM-BASED ADJUSTMENTS
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    if momentum == "cooling_down":
        # User is losing interest - need to re-engage
        talking_points.insert(0, "ğŸ”„ Ø­Ø§Ø³Ø³ Ø¥Ù†Ùƒ Ù…Ø­ØªØ§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ø¹ÙŠÙ†Ø©ØŸ Ù‚ÙˆÙ„ÙŠ Ø¨Ø§Ù„Ø¸Ø¨Ø· Ø§Ù„Ù„ÙŠ Ù†Ø§Ù‚ØµÙƒ.")
    elif momentum == "warming_up":
        # User is getting interested - push towards close
        talking_points.append("ğŸ¯ Ø£Ù†Ø§ Ø´Ø§ÙŠÙ Ø¥Ù†Ùƒ Ù…Ù‡ØªÙ… - Ù†Ø¹Ù…Ù„ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø¬Ø§ÙŠØ©ØŸ")
    
    # Modify based on urgency
    if urgency in [UrgencyLevel.URGENT, UrgencyLevel.READY_TO_ACT]:
        talking_points.append("Ø®Ù„ÙŠÙ†Ø§ Ù†ØªØ­Ø±Ùƒ Ø¯Ù„ÙˆÙ‚ØªÙŠ")
    
    # Modify based on data quality
    if top_property_verdict == "BARGAIN" and has_properties:
        talking_points.insert(0, "ğŸ”¥ Ù„Ù‚ÙŠØªÙ„Ùƒ Ù„Ù‚Ø·Ø© - ØªØ­Øª Ø³Ø¹Ø± Ø§Ù„Ø³ÙˆÙ‚")
    
    return {
        "strategy": strategy.value,
        "angle": angle,
        "talking_points": talking_points,
        "psychology_state": state.value,
        "urgency": urgency.value,
        "primary_message": talking_points[0] if talking_points else "",
        # V2 added fields
        "specific_objection": objection.value,
        "emotional_momentum": momentum,
    }


# Export
__all__ = [
    "PsychologicalState",
    "ObjectionType",  # V2: Granular objection classification
    "UrgencyLevel",
    "PsychologyProfile",
    "Strategy",
    "analyze_psychology",
    "semantic_classify_emotion",  # V2: LLM fallback classifier
    "determine_strategy",
    "get_psychology_context_for_prompt",
    "PSYCHOLOGY_PATTERNS",
    "OBJECTION_PATTERNS"  # V2: Objection patterns
]

